{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: This notebook was made for the Principles of Data Science course (DATA100).*\n",
    "\n",
    "_This is not for distribution oustide of this class._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Another alternative to data collection besides using APIs is through web scraping. In this notebook we will learn how to scrape a web page using `beautifulsoup` and `requests` library. We will be scaping http://books.toscrape.com/. A website that was specifically created in order for developers to learn how to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below retrieves the html page of a book entitled \"A Light in the Attic\". The html page was retrieved using the `requests` library. After retrieving, the html is passed on to the `beautifulsoup` parser. By using `beautifulsoup`, we are able to get specific information (ex. title, price, rating) of the book.\n",
    "\n",
    "Take a look at the html document printed by the script. What can you observe? Do you see any specific patterns that are repeating? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the html from one of the books in the website\n",
    "page = requests.get('http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html')\n",
    "\n",
    "#feed it into beautiful soup for parsing\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing though the html document can be overwhelming. Don't fret, as you gain more experience in scraping websites this will become more intuitive to you. Lets familiarize ourselves first with the typical structure of an HTML document. \n",
    "\n",
    "```\n",
    "<html>\n",
    "    <head>\n",
    "        <!--this is how comments are written in html-->\n",
    "        <!--we usually place css files under the head tag --> \n",
    "        <link href=\"../../static/oscar/css/styles.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
    "        <link href=\"../../static/oscar/js/bootstrap-datetimepicker/bootstrap-datetimepicker.css\" rel=\"stylesheet\"/>\n",
    "        <link href=\"../../static/oscar/css/datetimepicker.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <!-- this where the content of the web page is located -->\n",
    "        <!-- which means the information that you want to scrape will be located here -->\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "The html document is made up of tags each with an opening and closing tag. Typically it is made up of 3 main tags `html`, `head`, `body`. The html tag is a standard being followed to indicate that the document being created is html. The head tag would usually contain libraries or files that need to be imported into the document for example `CSS`(Cascading Style Sheets) files. `CSS` can be imagined as the libraries/files responsible for making your website pretty so things like color, shading, font settings can be found here. Lastly, the body tag is where the content of the page can be found. This is usually where we scrape the information from. \n",
    "\n",
    "Inside the body tag you can observe several types of tags. Some common tags can be found below: \n",
    "\n",
    "| HTML Tag | Description |\n",
    "| --- | --- |\n",
    "| div | The div tag is used to group together html elements that make up a component | \n",
    "| h1,h2,h3,h4,h5 | These are header tags, the smalelr the number the bigger the text that is shown on screen | \n",
    "| p | P stands for paragraph, this is where text content is usually placed | \n",
    "| a | a stands for anchor, this is where hyperlinks are placed | \n",
    "| img | imag stands for Image, this is where images are placed | \n",
    "| ul, ol, li | These are list tags, ul stands for unordered list, ol for ordered list ,li for list | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful tool to aid you in web scraping is the inspector tool that is available in browsers. This can be accessed by pressing `f12`. After pressing a toolbar should pop up on your browser. With the inspector tool you can hover your mosue around the web page and it will automatically show you which part of the html document you are looking at. This makes scraping easier since you don't have to read through the entire html document.\n",
    "\n",
    "Take for example the image below, I hovered my mouse on the container of the book title and on the right side you can see the different tags that make up the book title component. So if we were interested in getting the title, and price we know that the title is placed inside a `h1` tag while the price is placed inside a `p` tag. You can observe also that these tags have attributes called `class`. The class attribute is connected to the css file that was imported in the head tag which allows the browser to know how to render the tag. The class attribute is also useful for us when scraping since it allows us to narrow down the tag that we want to get.  \n",
    "\n",
    "<img src=\"chrome_dev_tools.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a general undesrtanding of the html document let us use beautifulsoup to get information from the website. The most common function that we will use from this library is `find`. This function will return the first tag that matches the criteria given to it. Let's use it to get the title of the book and the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the find function returns the tag of the element if we want to remove the tags we call the .text attribute \n",
    "print(soup.find('h1'))\n",
    "print(soup.find('h1').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The find function also accepts attributes to look for inside the tag. For the script below we indicate that we are looking for the paragraph tag who has a class called price_color. This allows our search to be more targeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('p', attrs={'class':'price_color'}))\n",
    "print(soup.find('p', attrs={'class':'price_color'}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another function that is available for us is the find_all function. This returns a list of all elements that match the tag placed inside the find_all function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_results = soup.find_all('p')\n",
    "p_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that it is a list we can use an index to retrieve the information that we need. Take for example if we are only interested in getting the product description we can just get the last element from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_results[-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get information relative to a tag using the next_sibling function. For example we want to get how many are in stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('p', attrs={'class':'price_color'}).next_sibling.next_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, tables are a common structure found in websites which contain the information that we need. In order to retreive the data we have to iterate over the different rows within the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_res = soup.find('table', class_=\"table-striped\")\n",
    "print(table_res.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in table_res.find_all('tr'):\n",
    "    header = row.find('th').text\n",
    "    data = row.find('td').text\n",
    "    print(f\"{header} = {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
