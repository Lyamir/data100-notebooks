{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with `pandas`\n",
    "\n",
    "By now, you have some experience in using the `pandas` library which will be very helpful in this module. In this notebook, we will explore more of `pandas` but in the context of data wrangling. To be specific, we will be covering the following topics:\n",
    "- Downloading data within a notebok\n",
    "- Reading in data\n",
    "- Descriptive statistics\n",
    "- Data wrangling\n",
    "- Filtering\n",
    "- Aggregation\n",
    "- Merging\n",
    "\n",
    "_Note: **Data wrangling** is another term commonly used for data cleaning & processing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we import the necessary libraries first. Always remember to import first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The Philippines has an Open Data portal: https://data.gov.ph\n",
    "\n",
    "In this notebook, we'll be using the [Public Elementary School Enrollment Statistics](https://data.gov.ph/?q=dataset/public-elementary-school-enrollment-statistics) provided by the Department of Education. The page contains two files. \n",
    "\n",
    "You can manually download both files from the websites and save them to the same folder as this notebook.\n",
    "\n",
    "Alternatively, we can also download these programmatically using `curl`. For **MacOS** users, this is more or less installed by default, but for **Windows**, you can follow the [instructions here](https://idratherbewriting.com/learnapidoc/docapis_install_curl.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://data.gov.ph/sites/default/files/deped_publicelementaryenrollment2012.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://data.gov.ph/sites/default/files/deped_publicelementaryenrollment2012.csv\n",
    "        \n",
    "https://data.gov.ph/sites/default/files/depend_publicelementaryenrollment2015.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the filename in a variable\n",
    "filenames = ['deped_publicelementaryenrollment2012.csv', 'depend_publicelementaryenrollment2015.csv']\n",
    "\n",
    "for file in filenames:\n",
    "    # check first if the file exists already\n",
    "    # to avoid redownloading if it's there\n",
    "    if os.path.exists(file):\n",
    "        print('File exists!')\n",
    "    else:\n",
    "        # since it doesn't exist yet, we try to download the file\n",
    "        print('File not found! Filename: {}'.format(file))\n",
    "        print('Proceed with download...')\n",
    "\n",
    "        # one way to download is through the command line tool curl\n",
    "        val = os.system('curl -O https://data.gov.ph/sites/default/files/' + file)\n",
    "        print(val)  ## 0 return value means success\n",
    "        \n",
    "        # final sanity check that it actually exists\n",
    "        if os.path.exists(file):\n",
    "            print('File downloaded and exists in current folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "    `os.system('curl -O https://data.gov.ph/sites/default/files/' + file)`\n",
    "\n",
    "The above code downloads the file using a tool called `curl`. It allows us to transfer data to and from a server.\n",
    "\n",
    "Notice the `-O` (dash capital letter o) in the command. This specifies that we want the file to be saved as it is named from the source. If this option was not specified, the output of the file will simply be displayed and not saved.\n",
    "\n",
    "Another option is to specify your own filename.\n",
    "\n",
    "    curl <url> -o <filename>\n",
    "\n",
    "*This uses the lowercase o instead of an uppercase O.*\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Why do it this way?**\n",
    "\n",
    "We want to avoid downloading the file again and again when we include the file download in our notebook. When we shutdown the Jupyter server, the kernels get reset when we fire it up again. To make sure our code is reproducible and avoid unnecessary waiting time for the download to complete when running the notebook, it's good to have a check first if the files we plan to use are existing in the path specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "In the previous modules, we have already demonstrated how to read files using `pandas`. For more details, run the cells below to display the documentations for the commonly used functions for reading files. Try to **read the documentation** to see if what you're trying to do is something that can already done by a library. Or you could simply **google** your concern. Most of the times, someone has already encountered the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, the encoding is utf-8, but since the data has some latin characters\n",
    "# the encoding argument needs to be updated\n",
    "# list of encodings can be found here https://docs.python.org/2.4/lib/standard-encodings.html\n",
    "# read more about encodings here http://kunststube.net/encoding/\n",
    "deped2012 = pd.read_csv('deped_publicelementaryenrollment2012.csv', encoding='latin1')\n",
    "\n",
    "# the head function provides a preview of the first 5 rows of the data\n",
    "deped2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the other file too\n",
    "deped2015 = pd.read_csv('depend_publicelementaryenrollment2015.csv', encoding='latin1')\n",
    "deped2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin exploring the data...\n",
    "\n",
    "Some of the most common questions to ask **first** before proceeding with your data is to know the basic details of what's **in** the data. This is an important first step to verify what you see in the preview (`head`) and what's in the entire file.\n",
    "\n",
    "* How many rows and columns do we have? \n",
    "* What is the data type of each column? \n",
    "* What is the most common value? Mean? Standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `shape`\n",
    "\n",
    "A `pandas` `DataFrame` is essentially a 2D `numpy` array. Using the `shape` attribute of the `DataFrame`, we can easily check the dimensions of the data file we read. It returns a tuple of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the `deped_publicelementaryenrollment2012.csv` file has 463,908 rows and 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dtypes` \n",
    "`dtypes` lets you check what data type each column is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that everything except `school_id` and `enrollment` is type `object`. In Python, a String is considered an `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `describe()`\n",
    "`describe()` provides the basic descriptive statistics of the`DataFrame`. By default, it only includes the columns with numerical data. Non-numerical columns are omitted but there are arguments that shows the statistics related to non-numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default we see the **descriptive statistics** of the nnumerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But by specifying the `include` argument, we can see the descriptive statistics of the specific data type we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "After looking at the basic information about the data, let's see how \"clean\" the data is.\n",
    "\n",
    "#### Common Data Problems (from slides)\n",
    "1. Missing values\n",
    "2. Formatting issues / data types\n",
    "3. Duplicate records\n",
    "4. Varying representation / Handle categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `isna()` / `isnull()`\n",
    "\n",
    "To check if there's any missing values, `pandas` provides these two functions to detect them. This actually maps each individual cell to either True or False.\n",
    "\n",
    "#### `dropna()`\n",
    "\n",
    "To remove any records with missing values, `dropna()` may be used. It has a number of arguments to help narrow down the criteria for removing the records with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.isna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.dropna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are no null values which is great, but in most real-world datasets, expect null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012_dropped = deped2012.dropna(inplace=False)\n",
    "deped2012.shape, deped2012_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above that shape is dimension because nothing happened after applying `dropna` as there are no null values to begin with. But what if there's a null value in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an ILLUSTRATION to show how to handle nan values. Don't change values to NaN unless NEEDED.\n",
    "deped2012_copy = deped2012.copy()  # We first make a copy of the dataframe\n",
    "deped2012_copy.iloc[0,0] = np.nan  # We modify the COPY (not the original)\n",
    "deped2012_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There null value is now reflected as shown in the output above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012_dropped = deped2012_copy.dropna(inplace=False)\n",
    "deped2012_copy.shape, deped2012_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'dropped' dataframe now has a lower number of rows compared to the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `duplicated()` --> `drop_duplicates()`\n",
    "\n",
    "The `duplicated()` function returns the duplicated rows in the `DataFrame`. It also has a number of arguments for you to specify the subset of columns. \n",
    "\n",
    "`drop_duplicates()` is the function to remove the duplicated rows found by `duplicated()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.drop_duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.duplicated(subset=['school_id', 'year_level', 'gender']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying representation\n",
    "\n",
    "For categorical or textual data, unless the options provided are fixed, misspellings and different representations may exist in the same file.\n",
    "\n",
    "To check the unique values of each column, a `pandas` `Series` has a function `unique()` which returns all the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['year_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015['year_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015['province'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `replace()`\n",
    "\n",
    "To fix varying representation issues, we can create a value mapping to replace one set with another to make sure these values match. Using the `replace()` method of `pandas`, it will update the values in the `DataFrame` according to the key-value pair. The value to be replaced is the key and the new value is the value in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_map = {\n",
    "    'I (Ilocos Region)': 'Region I - Ilocos Region', \n",
    "    'II (Cagayan Valley)': 'Region II - Cagayan Valley', \n",
    "    'III (Central Luzon)': 'Region III - Central Luzon',\n",
    "    'IV-A (CALABARZON)': 'Region IV-A - CALABARZON', \n",
    "    'IV-B (MIMAROPA)': 'Region IV-B - MIMAROPA', \n",
    "    'V (Bicol Region)': 'Region V - Bicol Region',\n",
    "    'VI (Western Visayas)': 'Region VI - Western Visayas', \n",
    "    'VII (Central Visayas)': 'Region VII - Central Visayas',\n",
    "    'VIII (Eastern Visayas)': 'Region VIII - Eastern Visayas', \n",
    "    'IX (Zamboanga Peninsula)': 'Region IX - Zamboanga Peninsula',\n",
    "    'X (Northern Mindanao)': 'Region X - Northern Mindanao', \n",
    "    'XI (Davao Region)': 'Region XI - Davao Region', \n",
    "    'XII (SOCCSKSARGEN)': 'Region XII - SOCCSKSARGEN',\n",
    "    'XIII (Caraga)': 'CARAGA - CARAGA', \n",
    "    'ARMM (Autonomous Region in Muslim Mindanao)': 'ARMM - Autonomous Region in Muslim Mindanao',\n",
    "    'CAR (Cordillera Administrative Region)': 'CAR - Cordillera Administrative Region',\n",
    "    'NCR (National Capital Region)': 'NCR - National Capital Region' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['region'] = deped2012['region'].replace(region_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Data\n",
    "\n",
    "High data granularity is great for a detailed analysis. However, data is usually summarized or aggregated prior to visualization. `pandas` also provides an easy way to summarize data based on the columns you'd like using the `groupby` function.\n",
    "\n",
    "We can call any of the following when grouping by columns:\n",
    "- count()\n",
    "- sum()\n",
    "- min()\n",
    "- max()\n",
    "- std()\n",
    "\n",
    "For columns that are categorical in nature, we can simply do `df['column'].value_counts()`. This will give the frequency of each unique value in the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of region instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.groupby('region')['school_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.groupby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of enrollments per grade level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.groupby(\"year_level\")['enrollment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice! \n",
    "\n",
    "Let's try to get the following:\n",
    "1. Total number of enrolled students per region and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.groupby(['region', 'gender'], as_index=False)['enrollment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Total number of enrolled students per year level and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.groupby(['year_level', 'gender']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n",
    "There are multiple ways to filter and select data, you can use the slicing method or your can use the query method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015[deped2015.year_level == 'grade 6'] #slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.query(\"year_level=='grade 6'\") #querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015[(deped2015.year_level=='grade 6') & (deped2015.school_id == 100004)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.query(\"year_level == 'grade 6' & school_id == 100004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.query(\"year_level == 'grade 6' | year_level == 'grade 5'\")[['region', 'province']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data\n",
    "\n",
    "Data are sometimes separated into different files or additional data from another source can be associated to another dataset. `pandas` provides means to combine different `DataFrames` together (provided that there are common variables that it can connect them to.\n",
    "\n",
    "#### `pd.merge`\n",
    "`merge()` is very similar to database-style joins. `pandas` allows merging of `DataFrame` and **named** `Series` objects together. A join can be done along columns or indexes.\n",
    "\n",
    "#### `pd.concat`\n",
    "`concat()` on the other hand combines `pandas` objects along a specific axis.\n",
    "\n",
    "#### `df.append`\n",
    "`append()` basically adds the rows of another `DataFrame` or `Series` to the end of the caller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.append?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the append..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012 = deped2012.groupby('school_id', as_index=False).sum()\n",
    "stats2015 = deped2015.groupby('school_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2015.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012['year'] = 2012\n",
    "stats2015['year'] = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.append(stats2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that it only just added the 2015 dataframe to the end of the 2012 dataframe. This only works if you want to attach rows at the end of the dataframe that share the same columns and would make sense to append. In this case, we needed to add the column `year` to help differentiate the schools for 2012 and 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice Example (for merging)\n",
    "\n",
    "The task is to compare the enrollment statistics of the elementary schools between 2012 and 2015. \n",
    "\n",
    "1. Get the total number of enrolled students per school for each year\n",
    "2. Merge the two `DataFrame`s together to show the summarized statistics for the two years for all schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012 = deped2012.groupby('school_id', as_index=False).sum()\n",
    "stats2015 = deped2015.groupby('school_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflect!\n",
    "\n",
    "Are the number of rows for both `DataFrames` the same or different? What's the implication if they're different?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell is the wrong way of merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(stats2012, stats2015)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "What happened to all the rows of schools? How did we have only these rows left?\n",
    "\n",
    "---\n",
    "We need to now merge these two `DataFrame` properly! We only want to merge on the column `school_id`. Even though the `enrollment` column is the same for both `DataFrames`, we don't want to use the `enrollment` column as a key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to merge is to use the `on=` argument to specify the column we want to merge on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = stats2012.merge(stats2015, on='school_id', how='outer')\n",
    "merged.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the documentation for `merge()`, there's a parameter for suffixes for overlapping column names. If we want to avoid the \"messy\" suffixes, we can choose to rename columns prior to merging.\n",
    "\n",
    "One way is to assign an array to the columns object representing the column names for ALL columns.\n",
    "\n",
    "```ipython\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']\n",
    "```\n",
    "\n",
    "But this is not good if you have too many columns... `pandas` has a function `rename()` in which we can pass a \"mappable\" dictionary for the columns. The `inplace` parameter helps in renaming it and assigns the changed `DataFrame` back to the same variable.\n",
    "\n",
    "```ipython\n",
    "stats2012.rename(columns={'enrollment': '2012'}, inplace=True)\n",
    "stats2015.rename(columns={'enrollment': '2015'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the code above\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the two dataframes using different \"how\" parameters\n",
    "# how : {'left', 'right', 'outer', 'inner'}, default 'inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_res = pd.merge(stats2012, stats2015)\n",
    "inner_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the how parameter and observe the following: \n",
    "- shape of the dataframe \n",
    "- presence or absence of null values \n",
    "- number of schools dropped with respect to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_res = pd.merge(stats2012, stats2015, how=\"outer\")\n",
    "outer_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_res = pd.merge(stats2012, stats2015, how=\"left\")\n",
    "left_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_res = pd.merge(stats2012, stats2015, how=\"right\")\n",
    "right_res.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice exercise\n",
    "\n",
    "Now that we have more or less an idea of how to merge, filter and aggregate, we can start asking questions to explore our data. Below are sample questions we can ask with the datasets we have.\n",
    "\n",
    "For the following questions, let's just use the 2015 DepEd data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which region has the most number of schools? Does this region also have the most number of enrollees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2015.groupby('region')['school_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment2015 = deped2015.groupby(['region', 'school_id'], as_index=False)['enrollment'].sum()\n",
    "enrollment2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment2015.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment2015.groupby('region')['enrollment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which region has the least number of schools? Does this region also have the least number of enrollees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Which school has the least number of enrollees? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "1. We were able to \"fix\" the region names above, can you find other things that can be \"fixed\" in this dataset?\n",
    "2. Try merging the 2012 and the 2015 datasets according to the regions and compare their enrollment counts, by gender, by grade level, etc. \n",
    "\n",
    "Post your ideas on what to explore with these two datasets on the AnimoSpace. Like what questions would you like to ask and if the dataset can answer your questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
